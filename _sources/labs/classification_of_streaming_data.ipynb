{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1df36e",
   "metadata": {},
   "source": [
    "# Ewaluacja jednoklasowych algorytmów klasyfikacji w danych strumieniowych\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f9cd8",
   "metadata": {},
   "source": [
    "## Wstęp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be521b5f",
   "metadata": {},
   "source": [
    "Materiały do listy został zainspirowany tutorialem udostępnionych przez twórców biblioteki dotyczący klasyfikacji danych strumieniowych w niezbalansowanym ustawieniu [River - imbalanced learning tutorial](https://riverml.xyz/0.14.0/examples/imbalanced-learning/). \n",
    "\n",
    "Autorzy w swoich materiałach wykorzystują zbiór danych `CreditCard`, w którym zawarto informacje o oszustwach związanych z kartami kredytowymi. Zapoznajmy się teraz ze zbiorem danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d37d1c",
   "metadata": {},
   "source": [
    "### Przedstawienie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ef6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "\n",
    "ds = datasets.CreditCard()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394caca",
   "metadata": {},
   "source": [
    "Jak można wywnioskować z opisu transakcje opisane jako oszustwa stanowią jedynie **0.172%** zbioru, a dokładnie `492` z `284807` transakcji. Cechy V1-V28 są cechami otrzymanymi poprzez wykorzystanie transformacji PCA, ze względu na poufność danych transakcyjnych. `Time` oznacza czas pomiędzy każdą z transakcji a pierwszą oraz `Amount` która określa wartość transakcji. Wczytajmy teraz pierwszy rekord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d0a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_pretty\n",
    "\n",
    "display_pretty(list(ds.take(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c58c41",
   "metadata": {},
   "source": [
    "### Motywacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ad191",
   "metadata": {},
   "source": [
    "Autorzy materiałów co prawda przedstawiają rozwiązanie problemu oraz przedstawiają techniki radzenia sobie z niezbalansowanymi danymi, ale popełnili błędy w swoim układzie eksperymentalnym:\n",
    "\n",
    "**1) Autorzy nie uwzględnili specyfiki problemu przewidywania oszustw w transakcjach przeprowadzonych z wykorzystaniem kart płatniczych.**\n",
    "\n",
    "Autorzy stworzyli układ eksperymentalny w taki sposób, że model jest aktualizowany z pojawianiem się każdej transakcji. W przypadku tego problemu, w rzeczywistym systemie nie moglibyśmy wykorzystać takiego scenariusza, dlatego, że informacja dotycząca czy dana transakcja była oszustwem przychodzi ze sporym opóźnieniem. \n",
    "Sprawdzając regulamin jednego z operatorów transakcji, znajdujemy informacje, że konsument ma nawet `120` dni na złożenie reklamacji, a procedura może wynieść nawet kilkadziesiąt kolejnych dni.\n",
    "\n",
    "**2) Autorzy wykorzystali metrykę ROCAUC do zmierzenia jakości algorytmu danych niezbalansowanych**\n",
    "\n",
    "Metryka ROCAUC nie jest metryką stworzoną do obsługi takiego scenariusza, w danych niezbalansowanych powinno stosować się metrykę [Precesion Recall Curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html). Więcej o powodach korzystania z PRC można przeczytać m.in. w następującym artykule https://towardsdatascience.com/imbalanced-data-stop-using-roc-auc-and-use-auprc-instead-46af4910a494\n",
    "\n",
    "Dodatkowo sprawdzimy przydatność cechy `Time`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8c2e4",
   "metadata": {},
   "source": [
    "## Klasyfikacja danych strumieniowych w bibliotece river"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee928143",
   "metadata": {},
   "source": [
    "### Wstęp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2dbc5b",
   "metadata": {},
   "source": [
    "Rozważmy na początku kod który przedstawiają autorzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e38557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import linear_model\n",
    "from river import preprocessing\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "\n",
    "model = preprocessing.StandardScaler() | linear_model.LogisticRegression()\n",
    "\n",
    "ds = datasets.CreditCard()\n",
    "auc = metrics.ROCAUC()\n",
    "evaluate.progressive_val_score(ds, model, auc)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2c5e7",
   "metadata": {},
   "source": [
    "Tak jak wspomniane zostało wcześniej powyższa ewaluacja nie uwzględnia opóźnień w etykietach. Jednakże trzeba mieć na uwadze, że metoda [`progressive_val_score`](`https://riverml.xyz/0.14.0/api/evaluate/progressive-val-score/) zawiera parametr `delay`, który odpowiada za ten scenariusz. Jednakże w przypadku tego zbioru nie jesteśmy tego przetestować, ze względu na brak informacji w zbiorze. Stworzymy własny alternatywny scenariusz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac045fa2",
   "metadata": {},
   "source": [
    "### Poprawa scenariuszu ewaluacyjnego\n",
    "\n",
    "Poprawmy teraz scenariusz ewaluacji:   \n",
    " - Pierwsze 200000 transakcji wykorzystamy w celu treningu modelu;\n",
    " - Pozostałe rekordy wykorzystamy do inferencji modelu i do przeliczenia metryk;\n",
    " - Niestety biblioteka `river` nie posiada implementacji wspomnianej wcześniej metryki `PRC`, dlatego wykorzystamy metrykę `Macro F1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b2eb81",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "\n",
    "Przy przetwarzaniu danych strumieniowych i danych temporalnych często stosuje się podział przez konkretne daty zamiast polegać na liczbie rekordów.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08fd7e2",
   "metadata": {},
   "source": [
    "Niestety obiekt typu `river.datasets.base.Dataset` nie pozwala na manipulacje zbiorem, dlatego stworzymy własny iterator, w którym musimy dodatkowo wykonać konwersję cech. W celach porównawczych stworzymy dwie wersje iteratora jedną zawierającą cechę `Time` i drugą bez tej cechy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator\n",
    "from typing import Any\n",
    "\n",
    "from river.stream import iter_csv\n",
    "\n",
    "\n",
    "def get_ds_iter() -> Iterator[Any]:\n",
    "    return iter_csv(\n",
    "        ds.path,\n",
    "        converters={\n",
    "            \"Amount\": float,\n",
    "            \"Class\": int,\n",
    "            **{f\"V{i}\": float for i in range(1, 29)},\n",
    "        },\n",
    "        drop=[\"Time\"],\n",
    "        target=\"Class\",\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ds_iter_with_time() -> Iterator[Any]:\n",
    "    return iter_csv(\n",
    "        ds.path,\n",
    "        converters={\n",
    "            \"Amount\": float,\n",
    "            \"Class\": int,\n",
    "            \"Time\": float,\n",
    "            **{f\"V{i}\": float for i in range(1, 29)},\n",
    "        },\n",
    "        target=\"Class\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42095195",
   "metadata": {},
   "source": [
    "#### Uczenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from river.metrics import MacroF1\n",
    "\n",
    "ds_iter = get_ds_iter()\n",
    "train_split_idx = 200_000\n",
    "model = preprocessing.StandardScaler() | linear_model.LogisticRegression()\n",
    "f1_metric = MacroF1()\n",
    "\n",
    "pbar = tqdm(desc=\"Training\", total=train_split_idx)\n",
    "for idx, (x, y) in enumerate(ds_iter):\n",
    "    pbar.update(1)\n",
    "\n",
    "    y_pred = model.predict_one(x)\n",
    "    f1_metric = f1_metric.update(y_true=y, y_pred=y_pred)\n",
    "    model = model.learn_one(x, y)\n",
    "    if idx + 1 == train_split_idx:\n",
    "        pbar.close()\n",
    "        break\n",
    "\n",
    "\n",
    "f1_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57644f",
   "metadata": {},
   "source": [
    "#### Ewaluacja modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8437534",
   "metadata": {},
   "source": [
    "Pozostaje nam dokonać ewaluacji danych testowych. Podczas inferencji możemy dodatkowo wykorzystać metodę [`compose.pure_inference_mode`](https://riverml.xyz/0.14.0/api/compose/pure-inference-mode/), która zapewnia że żaden z elementów naszego pipelinu nie zostanie zaaktualizowany i zostanie wykorzystana czysta inferencja. Wykorzystajmy ją w naszym scenariuszu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import compose\n",
    "\n",
    "test_f1_metric = MacroF1()\n",
    "with compose.pure_inference_mode():\n",
    "    for idx, (x, y) in tqdm(\n",
    "        enumerate(ds_iter),\n",
    "        desc=\"Inference\",\n",
    "    ):\n",
    "        y_pred = model.predict_one(x)\n",
    "        test_f1_metric = test_f1_metric.update(y_true=y, y_pred=y_pred)\n",
    "\n",
    "test_f1_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aade53",
   "metadata": {},
   "source": [
    "#### Refactor funkcjonalności uczenia i ewaluacji do klasy `RiverTrainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9306f",
   "metadata": {},
   "source": [
    "Opakujmy teraz to w jedną klasę aby poprawić czytelność kodu do dalszych porównań. W celach porównawczych dodano metrykę AUC oraz uzupełniono metody o elementy potrzebne do analiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466918f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Generator, Any, List, Optional, Union\n",
    "\n",
    "from river.compose.pipeline import Pipeline\n",
    "from river.metrics.base import Metric, Metrics\n",
    "from river.metrics import ROCAUC\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RiverTrainer:\n",
    "    pipeline: Pipeline\n",
    "    data_iter: Iterator[Any]\n",
    "    train_split_idx: Optional[int]\n",
    "    train_metrics: Union[Metric, Metrics]\n",
    "    eval_metrics: Optional[Union[Metric, Metrics]] = None\n",
    "    auc: bool = False\n",
    "    train_auc_metric: Optional[ROCAUC] = field(init=False, default=None)\n",
    "    eval_auc_metric: Optional[ROCAUC] = field(init=False, default=None)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if self.auc:\n",
    "            self.train_auc_metric = ROCAUC()\n",
    "            if train_split_idx:\n",
    "                self.eval_auc_metric = ROCAUC()\n",
    "\n",
    "    def train(self) -> None:\n",
    "        if self.train_split_idx:\n",
    "            pbar = tqdm(desc=\"Training\", total=train_split_idx)\n",
    "        else:\n",
    "            pbar = tqdm(desc=\"Training\")\n",
    "        for idx, (x, y) in enumerate(self.data_iter):\n",
    "            pbar.update(1)\n",
    "\n",
    "            y_pred = self.pipeline.predict_one(x)\n",
    "            if self.train_auc_metric:\n",
    "                y_proba = self.pipeline.predict_proba_one(x)\n",
    "                self.train_auc_metric = self.train_auc_metric.update(\n",
    "                    y_true=y, y_pred=y_proba\n",
    "                )\n",
    "\n",
    "            if self.train_metrics:\n",
    "                self.train_metrics = self.train_metrics.update(y_true=y, y_pred=y_pred)\n",
    "            self.pipeline = self.pipeline.learn_one(x, y)\n",
    "            if self.train_split_idx and idx + 1 == self.train_split_idx:\n",
    "                break\n",
    "\n",
    "    def test(self) -> None:\n",
    "        with compose.pure_inference_mode():\n",
    "            for idx, (x, y) in tqdm(\n",
    "                enumerate(self.data_iter),\n",
    "                desc=\"Inference\",\n",
    "            ):\n",
    "                y_pred = self.pipeline.predict_one(x)\n",
    "                if self.eval_auc_metric:\n",
    "                    y_proba = self.pipeline.predict_proba_one(x)\n",
    "                    self.eval_auc_metric = self.eval_auc_metric.update(\n",
    "                        y_true=y, y_pred=y_proba\n",
    "                    )\n",
    "                if self.eval_metrics:\n",
    "                    self.eval_metrics = self.eval_metrics.update(\n",
    "                        y_true=y, y_pred=y_pred\n",
    "                    )\n",
    "\n",
    "    def evaluate(self) -> None:\n",
    "        self.train()\n",
    "        if self.train_split_idx:\n",
    "            self.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab866ea",
   "metadata": {},
   "source": [
    "#### Uczenie modelu z wykorzystaniem naszego `RiverTrainera`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88cb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RiverTrainer(\n",
    "    pipeline=(preprocessing.StandardScaler() | linear_model.LogisticRegression()),\n",
    "    data_iter=get_ds_iter(),\n",
    "    train_split_idx=200_000,\n",
    "    train_metrics=MacroF1(),\n",
    "    eval_metrics=MacroF1(),\n",
    "    auc=False,\n",
    ")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e84a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\", trainer.train_metrics, \"\\nTest\", trainer.eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7bdca",
   "metadata": {},
   "source": [
    "#### Test poprawności `RiverTrainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504adbd",
   "metadata": {},
   "source": [
    "Porówanie obiektu `RiverTrainer` z metodą `progressive_val_score`. W tym celu stworzymy nowy iterator zawierający zmienną `Time`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339df1d",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Scenariusz wyłącznie w celu zweryfikowania poprawności kodu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = preprocessing.StandardScaler() | linear_model.LogisticRegression()\n",
    "\n",
    "river_auc = metrics.ROCAUC()\n",
    "evaluate.progressive_val_score(ds, model, river_auc)\n",
    "\n",
    "\n",
    "trainer = RiverTrainer(\n",
    "    pipeline=(preprocessing.StandardScaler() | linear_model.LogisticRegression()),\n",
    "    data_iter=get_ds_iter_with_time(),\n",
    "    train_split_idx=None,\n",
    "    train_metrics=None,\n",
    "    eval_metrics=None,\n",
    "    auc=True,\n",
    ")\n",
    "trainer.evaluate()\n",
    "\n",
    "print(\"River evaluation\", river_auc, \"Custom evaluation\", trainer.train_auc_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda55bb9",
   "metadata": {},
   "source": [
    "### Analizy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796073b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f92ce",
   "metadata": {},
   "source": [
    "#### Model bez uwzględnienia cechy `Time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15409f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RiverTrainer(\n",
    "    pipeline=(preprocessing.StandardScaler() | linear_model.LogisticRegression()),\n",
    "    data_iter=get_ds_iter(),\n",
    "    train_split_idx=200_000,\n",
    "    train_metrics=MacroF1(),\n",
    "    eval_metrics=MacroF1(),\n",
    "    auc=False,\n",
    ")\n",
    "trainer.evaluate()\n",
    "results[\"Without Time Feature\"] = {\n",
    "    \"train\": trainer.train_metrics.get(),\n",
    "    \"test\": trainer.eval_metrics.get(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139ac72",
   "metadata": {},
   "source": [
    "#### Model z uwzględnieniem cechy `Time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RiverTrainer(\n",
    "    pipeline=(preprocessing.StandardScaler() | linear_model.LogisticRegression()),\n",
    "    data_iter=get_ds_iter_with_time(),\n",
    "    train_split_idx=200_000,\n",
    "    train_metrics=MacroF1(),\n",
    "    eval_metrics=MacroF1(),\n",
    "    auc=False,\n",
    ")\n",
    "trainer.evaluate()\n",
    "results[\"With Time Feature\"] = {\n",
    "    \"train\": trainer.train_metrics.get(),\n",
    "    \"test\": trainer.eval_metrics.get(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329ba25",
   "metadata": {},
   "source": [
    "#### Model uczony na pełnych danych (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df_ds = pd.read_csv(ds.path)\n",
    "train_ds = df_ds[:200_000]\n",
    "test_ds = df_ds[200_000:]\n",
    "y_train = train_ds.pop(\"Class\")\n",
    "y_test = test_ds.pop(\"Class\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"logistic_regression\", LogisticRegression())]\n",
    ").fit(train_ds, y_train)\n",
    "\n",
    "train_y_pred = pipeline.predict(train_ds)\n",
    "test_y_pred = pipeline.predict(test_ds)\n",
    "\n",
    "results[\"Sklearn model\"] = {\n",
    "    \"train\": f1_score(y_true=y_train, y_pred=train_y_pred, average=\"macro\"),\n",
    "    \"test\": f1_score(y_true=y_test, y_pred=test_y_pred, average=\"macro\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecaf97b",
   "metadata": {},
   "source": [
    "#### Rezultaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cdb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed1727c",
   "metadata": {},
   "source": [
    "#### Podsumowanie wyników"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a157ac0",
   "metadata": {},
   "source": [
    "Na pierwszy rzut oka można byłoby dojść do następujących wniosków:   \n",
    "\n",
    "**1.** Logistyczna regresja uczona w trybie online ma dużo wyższą skuteczność niż jej które uczy na całości danych   \n",
    "**2.** Zastosowanie cechy `Time`, która określa upływ czasu od pierwszego zdarzenia polepsza jakość klasyfikacji\n",
    "   \n",
    "Ale czy aby na pewno?\n",
    "\n",
    "**Ad 1.** Podczas uczenia modeli pomiędzy bibliotekami skorzystano z innych optymalizatorów i hiperparametrów. Aby uczciwie odpowiedzieć na pytanie czy logistyczna rogresja uczona w trybie online rzeczywiście osiąge wyniki musielibyśmy użyć tych samych hiperparametrów metod i dopiero wtedy je ze sobą porównać. Jedyną różnicą powinien być jedynie tryb uczenia\n",
    "\n",
    "**Ad 2.** Sprawdźmy z jakiego okresu pochodzą dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aaaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "times = []\n",
    "for x, y in ds:\n",
    "    times.append(x[\"Time\"])\n",
    "\n",
    "print(\"Seconds elapsed\", np.max(times), \"\\nHours elapsed\", np.max(times) / 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc218ec",
   "metadata": {},
   "source": [
    "Dane pochodzą jedynie z dwóch dni, co może być za krótkim okresem żeby potwierdzić użyteczność tej zmiennej. Model może wykorzystać informacje o różnicach rozkładów pomiędzy dwoma dniami, co w tym przypadku może być uznane jako pewnego rodzaju artefakt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
