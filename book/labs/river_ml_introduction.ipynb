{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f16941b",
   "metadata": {},
   "source": [
    "# Wprowadzenie do biblioteki River"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3541b1ac",
   "metadata": {},
   "source": [
    "[River](https://github.com/online-ml/river) jest jedną z najbardziej rozszerzonych bibliotek z dziedziny online machine learning. Jest wynikiem połączenia dwóch bibliotek [creme](https://github.com/MaxHalford/creme) oraz [scikit-multiflow](https://github.com/scikit-multiflow/scikit-multiflow). Jest głównie napisana w języku Python, przy czym intensywne obliczeniowo operacje napisane są w języku Rust.\n",
    "\n",
    "Główna funkcjonalność biblioteki obejmuje m.in.:\n",
    "- Modele liniowe i klasyczne modele maszynowego uczenia \n",
    "- Wykrywanie anomalii i dryftu konceptu\n",
    "- Systemy rekomendycjne\n",
    "- Prognozowanie na podstawie szeregów czasowych\n",
    "- Uczenie niezbalansowanych danych\n",
    "- Klasteryzacja\n",
    "- Metryki i statystyki zadaptowane do dziedziny Online Machine Learning\n",
    "\n",
    "Najważniejsze linki:\n",
    "- Strona główna [[LINK]](https://riverml.xyz/0.14.0/)\n",
    "- Tutoriale [[LINK]](https://riverml.xyz/0.14.0/recipes/reading-data/)\n",
    "- Przykłady [[LINK]](https://riverml.xyz/0.14.0/examples/batch-to-online/)\n",
    "- Dokumentacja [[LINK]](https://riverml.xyz/0.14.0/api/overview/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fefcb",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "\n",
    "Materiały wraz z tutorialami zostały przygotowane w oparciu o biblioteke `river` w wersji 0.14\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbc612",
   "metadata": {},
   "source": [
    "## Dane w bibliotece river\n",
    "\n",
    "Dodatkowo, w bibliotce `river` zawarto pakiet zbiorów z dziedziny online machine learning wraz z potrzebnymi loaderami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43832df7",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "\n",
    "Pełną listę zbiorów można przejrzeć na stronie biblioteki [[LINK]](https://riverml.xyz/0.14.0/api/datasets/AirlinePassengers/)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5f586e",
   "metadata": {},
   "source": [
    "Funkcjanolność biblioteki nie ogranicza się tylko do udostępnionych zbiorów. W bibliotece znajdziemy obsługę wielu popularnych formatów danych takich jak np. numpy array, pliki csv czy bezpośrednie pobieranie danych z baz sql.\n",
    "\n",
    "Pełne przedstawienie formatów danych wspierających przez bibliotekę `river` przedstawiono w poniższej tabeli:\n",
    "\n",
    "| Format danych | Loader\n",
    "| --- | --- |\n",
    "| arff | [stream.iter_arff](https://riverml.xyz/0.14.0/api/stream/iter-arff/) |\n",
    "| numpy array | [stream.iter_array](https://riverml.xyz/0.14.0/api/stream/iter-array/)|\n",
    "| csv | [stream.iter_csv](https://riverml.xyz/0.14.0/api/stream/iter-csv/) |\n",
    "| LIBSVM | [stream.iter_libsvm](https://riverml.xyz/0.14.0/api/stream/iter-libsvm/) |\n",
    "| pandas DataFrame | [stream.iter_pandas](https://riverml.xyz/0.14.0/api/stream/iter-pandas/) |\n",
    "| sklearn dataset | [stream.iter_sklearn_dataset](https://riverml.xyz/0.14.0/api/stream/iter-sklearn-dataset/) |\n",
    "| sql | [stream.iter_sql](https://riverml.xyz/0.14.0/api/stream/iter-sql/) |\n",
    "| vaex DataFrame | [stream.iter_vaex](https://riverml.xyz/0.14.0/api/stream/iter-vaex/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527f0ee",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "W tutorialu wykorzystano zbiór danych [`MovieLens100K`](https://grouplens.org/datasets/movielens/100k/). Jest to zbiór danych przygotowany przez naukowców z University of Minnesota. Składa się z 100 000 ocen w skali 1-5 1682 filmów pochodzących od 943 użytkowników. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75fadee",
   "metadata": {},
   "source": [
    "### Podstawowe operacje na zbiorze danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13dcef",
   "metadata": {},
   "source": [
    "#### Wczytanie zbioru danych dostępnego w bibliotece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa401468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.datasets import MovieLens100K\n",
    "\n",
    "ds = MovieLens100K()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da300e",
   "metadata": {},
   "source": [
    "#### Dostęp do elementów zbioru \n",
    "Standardowy dostęp do elementów ze zbioru danych odbywa się za pomocą iteratora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04783683",
   "metadata": {},
   "source": [
    "W przypadku wykorzystania pętli, nie ma potrzeby tworzenia wcześniej iteratora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d6b77",
   "metadata": {},
   "source": [
    "```{hint}\n",
    "W celu przejrzystego wyświetlania danych została wykorzystana metoda [`display_pretty`](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.display_pretty) z modułu `IPython.display`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37095e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_pretty\n",
    "\n",
    "for x, y in ds:\n",
    "    display_pretty(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123aed2",
   "metadata": {},
   "source": [
    "W przypadku zbiorów danych udostępnionych przez bibliotekę, do dyspozycji mamy również metodę [`take`](https://riverml.xyz/0.14.0/api/datasets/base/Dataset/), która zwraca iterator na n pierwszych elementów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ds.take(k=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c454fc2",
   "metadata": {},
   "source": [
    "#### Wczytanie zbioru z pliku csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042a6e5",
   "metadata": {},
   "source": [
    "W celach ćwiczenia wczytamy zbiór danych bezpośrednio z pliku `csv`, ale wykorzystamy już wersję zbioru pobraną wcześniej. Aby dostać się do ścieżki pobranego zbioru odwołamy się do pola `path` z utworzonego wcześniej obiektu zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ds.path\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7c337",
   "metadata": {},
   "source": [
    "Do stworzenia iteratora z pliku skorzystamy z metody [`iter_csv`](https://riverml.xyz/0.14.0/api/stream/iter-csv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b91e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.stream import iter_csv\n",
    "\n",
    "ds = iter_csv(path, delimiter=\"\\t\")\n",
    "\n",
    "for x, y in ds:\n",
    "    display_pretty(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f4126",
   "metadata": {},
   "source": [
    "W porównaniu do poprzednego formatu możemy zauważyć nieporządane właściowości:\n",
    "- Wszystkie cechy wczytane są jako obiekty `string`\n",
    "- Cecha wyjściowa nie jest ustawiona, w razultacie otrzymujemy obiekt `None`\n",
    "\n",
    "Aby to poprawić, musimy zdefiniować dodatkowe argumenty, przekazane do metody `iter_csv`:\n",
    "- Mapowanie pól danych przekozujemy poprzez ustawienie parametru `converters`\n",
    "- Zdefiniowanie cechy wyjśćiowowej za pomocą parametru `target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.stream import iter_csv\n",
    "\n",
    "ds = iter_csv(\n",
    "    path,\n",
    "    delimiter=\"\\t\",\n",
    "    target=\"rating\",\n",
    "    converters={\n",
    "        \"rating\": float,\n",
    "        \"age\": int,\n",
    "        \"timestamp\": int,\n",
    "        \"release_date\": int,\n",
    "        \"title\": str\n",
    "    },\n",
    ")\n",
    "\n",
    "for x, y in ds:\n",
    "    display_pretty(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2394450d",
   "metadata": {},
   "source": [
    "Częściowo możemy to obejść poprzez wykorzystanie biblioteki `pandas` i metody [`iter_pandas`](https://riverml.xyz/0.11.1/api/stream/iter-pandas/). Pola danych zostaną automatycznie zmapowane za wyjątkiem zmiennej wyjściowej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a367b3d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river.stream import iter_pandas\n",
    "\n",
    "df = pd.read_csv(path, sep=\"\\t\", na_values=\"\")\n",
    "target = df.pop(\"rating\")\n",
    "ds = iter_pandas(df, y=target)\n",
    "\n",
    "for x, y in ds:\n",
    "    display_pretty(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75412aca",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Trzeba mieć na uwadze, że takie rozwiązanie nie jest w pełni podejściem `online`, ponieważ plik zostanie najpierw wczytany w całości. Rozwiązanie może być natomiast przydatne w trakcie eksperymentowania.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508786f",
   "metadata": {},
   "source": [
    "```{danger}\n",
    "\n",
    "Pomimo tego, że rozwiązania na pierwszy rzut oka wyglądają identycznie, tak na prawdę różnią się.\n",
    "Dlaczego? Pandas uzupełni brakujące wartości jako `nan`, który jest type float. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718f636",
   "metadata": {},
   "source": [
    "Sprawdźmy brakujące wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec332897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78688d",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Łącznie w całym zbiorze mamy 909 rekordów z co najmniej jedną brakującą wartością.\n",
    "```\n",
    "\n",
    "Sprawdźmy teraz dla jakich kolumn występowały brakujące wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db23cc0",
   "metadata": {},
   "source": [
    "Wartości brakujące występowały wyłącznie dla zmiennych tekstowych `title` oraz `occupation`\n",
    "W takim razie wystarczy wykorzystać metodę ```fillna(str)```, aby mieć domyślne zachowanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0736537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, sep=\"\\t\").fillna(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2a421",
   "metadata": {},
   "source": [
    "```{danger}\n",
    "Metoda `fillna()` powinna być jednak wykorzystana z rozwagą. Dodatkowe sprawdzenia były celowe, ponieważ jeżeli brakujące wartości pojawiły się w polach liczbowych pandas uzupełniłby je wartościami pustymi typu `str`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ad770",
   "metadata": {},
   "source": [
    "### Przetwarzanie zbioru danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79e227",
   "metadata": {},
   "source": [
    "#### Rozkład klas liczony od na całym wczytanym zbiorze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16048a",
   "metadata": {},
   "source": [
    "Zacznijmy od zbadania rozkładu klas. Zacznijmy od scenariusza, gdzie mamy dostęp do wczytanego pełnego zbioru (wykonanego za pomocą biblioteki `pandas`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "counter = Counter(target.values)\n",
    "sns.barplot(y=list(counter.values()), x=list(counter.keys()), errorbar=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606fe97",
   "metadata": {},
   "source": [
    "#### Obliczenie rozkładu klas z wykorzystaniem podejścia strumieniowego\n",
    "\n",
    "W bibliotece river możemy również obliczać statystyki w podejściu strumieniowym, czego przykładem jest [`Histogram`](https://riverml.xyz/0.14.0/api/sketch/Histogram/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb1ca3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from river.sketch import Histogram\n",
    "\n",
    "ds = iter_pandas(df, y=target)\n",
    "hist = Histogram(max_bins=5)\n",
    "\n",
    "for x, y in ds:\n",
    "    hist = hist.update(y)\n",
    "    \n",
    "sns.barplot(y=[b.count for b in hist], x=[b.left for b in hist], errorbar=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d63e0",
   "metadata": {},
   "source": [
    "#### Obliczenie rozkładu klas z wykorzystaniem licznika przybliżonego\n",
    "\n",
    "Często jednak wartości cech mogą nie mieć zdefiniowanego zakresu, ale pochodzić z całego zbioru liczb rzeczywistych. Obliczenie histogramu dla takich cech, może być zbyt kosztowne obliczeniowo. W takiej sytuacji możemy skorzystać z przybliżonego obliczenia wartości. W tym celu wykorzystamy klasę [Counter](https://riverml.xyz/0.14.0/api/sketch/Counter/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e6b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.sketch import Counter\n",
    "\n",
    "cms = Counter(seed=441)\n",
    "ds = iter_pandas(df, y=target)\n",
    "values = set()\n",
    "\n",
    "for x, y in ds:\n",
    "    cms = cms.update(int(y))\n",
    "    values.add(int(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db78ac4f",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "Obliczanie przybliżone licznika wystąpień poszczególnych wartości dla cech z ograniczonym podzbiorem, jakim jest cecha wyjściowa zbioru MovieLens100K może nie mieć uzsadnienia. Warto jednak pamiętać o takim rozwiązaniu przy cechach z dużą liczbą unikatowych wartości.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ea12c",
   "metadata": {},
   "source": [
    "#### Porównanie i podsumowanie dokładności podejść obliczenia rozkładu klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for rating in range(1, 6):\n",
    "    summary.append(\n",
    "        {\n",
    "            \"Counter\": counter[rating],\n",
    "            \"Counter (approx. version)\": cms[rating],\n",
    "            \"Histogram (streaming version)\": hist[rating - 1].count,\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(summary, index=range(1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91716558",
   "metadata": {},
   "source": [
    "W testowanym scenariuszu podejścia mają identyczne wyniki. Wynika to z ograniczonego rozmiaru zbioru (przyp. tylko 100K przypadków) oraz ograniczanego zakresu wartości całkowitych <1,5>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5e981",
   "metadata": {},
   "source": [
    "### Transformacje i ekstrakcja cech\n",
    "\n",
    "W tym podrozdziale omówimy podstawowe transformacje cech z wykorzystaniem river.\n",
    "\n",
    "Przypomnijmy jakie cechy znajdują się w zbiorze danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6734e",
   "metadata": {},
   "source": [
    "W ramach materiału wykonamy poniższych przekształceń:\n",
    "- Przekształcenie cech `timestamp` oraz `release_date`  z formatu `timestamp` do formatu `datetime`\n",
    "- Kompozycja cech\n",
    "- Modelowanie tematyczne tytułów filmów za pomocą algorytmu `LDA` \n",
    "- Tworzenie sekwencji kroków przetwarzania za pomocą klasy `Pipeline`\n",
    "- Agregacje cech z perspektywy danego użytkownika"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a78d6",
   "metadata": {},
   "source": [
    "#### Przekształcenie cech `timestamp` oraz `release_date`  z formatu `timestamp` do formatu `datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "ds = iter_pandas(df, y=target)\n",
    "\n",
    "for x, y in ds:\n",
    "    for date_column in (\"timestamp\", \"release_date\"):\n",
    "        x[date_column] = datetime.datetime.fromtimestamp(x[date_column] / 1e9)\n",
    "    \n",
    "    # `break` i `display_pretty` tylko w celach wyświetlenia pojedynczego rekordu\n",
    "    display_pretty(x)\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61495cb2",
   "metadata": {},
   "source": [
    "#### Kompozycja transformacji w jedną"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acdde5",
   "metadata": {},
   "source": [
    "Zamiast ręcznie pisać pętle możemy do przetwarzenia kilku kolumn, możemy je złożyć w jedną transformację za pomocą klasy [`TransformerUnion`](https://riverml.xyz/0.14.0/api/compose/TransformerUnion/). W tym calu musimy jednak mieć naszą metodę transformującą dane z wykorzystaniem klasy [`FuncTransformer`](https://riverml.xyz/0.14.0/api/compose/FuncTransformer/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa11fc",
   "metadata": {},
   "source": [
    "Zaczniemy od przepisania transformacji w klasę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905535e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "class TimestamptoDateConverter:\n",
    "    def __init__(self, col_name: str) -> None:\n",
    "        self.col_name = col_name\n",
    "\n",
    "    def __call__(self, x: Dict[str, Any]) -> Dict[str, datetime.datetime]:\n",
    "        # Do not assume incorrectly that something is a date in timestamp format\n",
    "        assert isinstance(x[self.col_name], int)\n",
    "        return {\n",
    "            f\"{self.col_name}_datetime\": datetime.datetime.fromtimestamp(\n",
    "                x[self.col_name] / 1e9\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91049e56",
   "metadata": {},
   "source": [
    "Teraz możemy utworzyć obiekt `FuncTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.compose import FuncTransformer\n",
    "\n",
    "FuncTransformer(TimestamptoDateConverter(col_name=\"timestamp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54e2ee",
   "metadata": {},
   "source": [
    "Teraz możemy złożyć transformację kilku cech za tworząc obiekt klasy [`TransformerUnion`](https://riverml.xyz/0.14.0/api/compose/TransformerUnion/) lub użyć operatora `+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9cc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.compose import TransformerUnion\n",
    "\n",
    "transformations = TransformerUnion(\n",
    "    FuncTransformer(TimestamptoDateConverter(col_name=\"timestamp\")),\n",
    "    FuncTransformer(TimestamptoDateConverter(col_name=\"release_date\")),\n",
    ")\n",
    "transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = (\n",
    "    FuncTransformer(TimestamptoDateConverter(col_name=\"timestamp\"))\n",
    "    + FuncTransformer(TimestamptoDateConverter(col_name=\"release_date\")),\n",
    ")\n",
    "transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e92fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformations = TransformerUnion(\n",
    "    FuncTransformer(TimestamptoDateConverter(col_name=\"timestamp\")),\n",
    "    FuncTransformer(TimestamptoDateConverter(col_name=\"release_date\")),\n",
    ")\n",
    "\n",
    "for x, y in ds:\n",
    "    x.update(transformations.learn_one(x).transform_one(x))\n",
    "\n",
    "    display_pretty(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47dfa4",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "\n",
    "Zamiast nadpisywać obiekty w powyższym kodzie, dodano nowe kolumny. \n",
    "To jak zostanie to obsłużone jest po naszej stronie. W niektórych przypadkach źródłowe kolumny usuwa się dopiero na końcu, ponieważ mogą być wymagane do transformacji innych cech.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a231f",
   "metadata": {},
   "source": [
    "#### Modelowanie tematyczne tytułów filmów za pomocą algorytmu `LDA` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.feature_extraction import BagOfWords\n",
    "from river.preprocessing import LDA\n",
    "\n",
    "ds = iter_pandas(df, y=target)\n",
    "\n",
    "bow = BagOfWords(on=\"title\")\n",
    "lda = LDA(seed=441)\n",
    "\n",
    "for x, y in ds:\n",
    "    bow_title = bow.transform_one(x)\n",
    "\n",
    "    # `break` i `display_pretty` tylko w celach wyświetlenia pojedynczego rekordu\n",
    "    display_pretty(lda.learn_transform_one(bow_title))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97480aa",
   "metadata": {},
   "source": [
    "#### Tworzenie sekwencji kroków przetwarzania za pomocą klasy `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7240b",
   "metadata": {},
   "source": [
    "Przekształcimy teraz LDA w jeden pipeline. Możemy to zrobić wykorzystując operator `|`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = BagOfWords(on=\"title\") | LDA(seed=441)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5477059",
   "metadata": {},
   "source": [
    "lub możemy bezpośrednio utworzyć obiekt klasy `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80877a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.compose.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(BagOfWords(on=\"title\"), LDA(seed=441))\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299ad81",
   "metadata": {},
   "source": [
    "Co uproszcza cały kod do następującej postaci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b255559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(BagOfWords(on=\"title\"), LDA(seed=441))\n",
    "\n",
    "ds = iter_pandas(df, y=target)\n",
    "for x, y in ds:\n",
    "    # `break` i `display_pretty` tylko w celach wyświetlenia pojedynczego rekordu\n",
    "    display_pretty(pipe.learn_one(x).transform_one(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3ad310",
   "metadata": {},
   "source": [
    "#### Agregacje cech z perspektywy danego użytkownika"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4a942",
   "metadata": {},
   "source": [
    "Aggregacje na strumieniu w bibliotece river wykonujemy za pomocą modułu [Agg](https://riverml.xyz/0.14.0/api/feature-extraction/Agg/)\n",
    "\n",
    "W ramach materiałów skupimy się na aggregacji zmiennej wyjściowej czyli oceny filmu. Wym celu wykorzystamy klasę [`TargetAgg`](https://riverml.xyz/0.14.0/api/feature-extraction/TargetAgg/), która dokonuje aggrecji cechy wyjściowej.\n",
    "\n",
    "Obliczmy teraz liczbę recenzji użytkowników dla pierwszych dwudziestu elementów strumienia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.feature_extraction import TargetAgg\n",
    "from river.stats import Count\n",
    "\n",
    "ds = iter_pandas(df.iloc[0:20], y=target[0:20])\n",
    "\n",
    "agg = TargetAgg(by=[\"user\"], how=Count())\n",
    "users_reviews_count = []\n",
    "for x, y in ds:\n",
    "    users_reviews_count.append({\"user\": x[\"user\"], **agg.learn_one(x, y).transform_one(x)})\n",
    "    \n",
    "users_reviews_count_df = pd.DataFrame(users_reviews_count)\n",
    "users_reviews_count_df.index.name = \"event_id\"\n",
    "users_reviews_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c6482",
   "metadata": {},
   "source": [
    "Aggregacje cechy z perspektywy całej historii użytkownika to tylko jedna z możliwości. Możemy zostosować aggregacje typu [`Rolling`](https://riverml.xyz/0.14.0/api/utils/Rolling/) która dokona aggregacji tylko na określonej liczbie rekordów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cb77e",
   "metadata": {},
   "source": [
    "Obliczmy teraz średnia ocena recenzji użytkownika z ostatnich pięciu rekordów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.utils import Rolling\n",
    "from river.stats import Mean\n",
    "\n",
    "ds = iter_pandas(df.iloc[0:20], y=target[0:20])\n",
    "\n",
    "agg = TargetAgg(by=[\"user\"], how=Rolling(Mean(), 5))\n",
    "user_rolling_review_mean = []\n",
    "for x, y in ds:\n",
    "    user_rolling_review_mean.append(\n",
    "        {\"user\": x[\"user\"], \"rating\": y, **agg.learn_one(x, y).transform_one(x)}\n",
    "    )\n",
    "\n",
    "user_rolling_review_mean_df = pd.DataFrame(user_rolling_review_mean)\n",
    "user_rolling_review_mean_df.index.name = \"event_id\"\n",
    "user_rolling_review_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27c3b8",
   "metadata": {},
   "source": [
    "Aggregacje również możemy grupować w pipeline za pomocą `TransformerUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a396e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = TargetAgg(by=[\"user\"], how=Rolling(Mean(), 5)) +  TargetAgg(by=[\"user\"], how=Count())\n",
    "aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24acbbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = iter_pandas(df.iloc[0:20], y=target[0:20])\n",
    "\n",
    "output = []\n",
    "for x, y in ds:\n",
    "    output.append({\"user\": x[\"user\"], \"rating\": y, **aggregations.learn_one(x, y).transform_one(x)})\n",
    "    \n",
    "output = pd.DataFrame(output)\n",
    "output.index.name = \"event_id\"\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
